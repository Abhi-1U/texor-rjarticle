---
title: "Converting LaTeX R Journal Articles into Rmarkdown using texor and rebib"
date: "2022-11-09"
abstract: >
  An abstract of less than 150 words.
draft: true
author:  
  # see ?rjournal_article for more information
  - name: Abhishek Ulayil
    affiliation: Student, Institute of Actuaries of India
    address:
    - Mumbai, India
    orcid: 0009-0000-6935-8690
    email: perricoq@outlook.com
  - name: Mitch O'Hara-Wild
    affiliation: Monash University
    address:
    - Melbourne, Australia
    orcid: 0000-0001-6729-7695
    email: mail@mitchelloharawild.com
  - name: Christophe Dervieux
    affiliation: Posit PBC
    address:
    - Paris, France
    orcid: 0000-0003-4474-2498
    email: christophe.dervieux@gmail.com
  - name: Heather Turner
    affiliation: University of Warwick
    address:
    - Newport, United Kingdom
    orcid: 0000-0002-1256-3375
    email: ht@heatherturner.net
  - name: Dianne Cook
    affiliation: Monash University
    address:
    - Melbourne, Australia
    orcid: 0000-0002-3813-7155
    email: dicook@monash.edu
type: package
output: 
  rjtools::rjournal_web_article:
    web_only: yes
    self_contained: yes
    toc: no
bibliography: RJreferences.bib

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(plotly)
library(ggplot2)
```

# Introduction

The R Journal is the primary open-access outlet for publications produced by the R community. It was born in 2008, evolving from a newsletter, that ran from 2001, into a more formal article publication to encourage documenting statistical computing research. 

The format is constantly evolving. Early articles were typeset using LateX [@latex], from a specific, but changing, template. This requires that code is separated from the documentation, and there is a chance that code chunks in the paper don't reproduce the results reported. With the emergence of dynamic document systems like R Markdown [@rmarkdown] a tight-coupling of code and documentation is possible. Code chunks are dynamically executed when the document is typeset using a system like \CRANpkg{knitr} [@knitr], making reporting of computing research more reproducible. 

In 2019, with the help of funding from the R Consortium it was decided that it was time to update operations. One aspect of this was to change from LaTeX paper submissions to a more reproducible format, where code was embedded in the document, and the output could be both HTML and pdf. There are numerous benefits of HTML format: 

1. Articles can include interactive graphics and tables.
2. The format is more accessible to screen readers making the work more accessible to vision-impaired researchers.

<!-- traditional HTML is the most universally accessible format - Australian Human Rights Commission https://humanrights.gov.au/our-work/disability-rights/world-wide-web-access-disability-discrimination-act-advisory-notes-ver and https://printdisability.org -->

This latter point is a reason to consider converting all of the legacy articles into HTML. 

A key decision for creating conversion software was to decide to directly convert LaTeX to HTML, or PDF to HTML, or LaTeX to R Markdown, and then use the current journal tools to create the HTML. The latter approach was decided to be the most versatile and useful. If an article can be converted from LaTeX to R Markdown, it would help authors make the transition to reproducible publishing, beyond what the R Journal needed. Once an article is in R Markdown format it can be adapted to include the code for dynamic execution.

In addition to article format, changes to the web site structure were important for delivering the publication. Web site architectures are also constantly evolving, and the emergence of \CRANpkg{distill} [@distill] allows for the journal web site to optimally deliver R Markdown articles.

The \CRANpkg{rjtools} was developed to create articles using R Markdown for the R Journal, and to embed them into the journal web site. The packages described here, \CRANpkg{texor} and \CRANpkg{rebib} describes software to convert legacy LaTeX format articles into Rmarkdown, so that they can be rendered in HTML in the new web site. 

The paper is organised as follows. Section XXX gives an overview of the conversion process. Section XXX describes examples of pre-processing using regular expressions, and section XXX provides examples of post-processing using lua filters. Section XXX describes tools to do special handling of bibliography files. Section XXX runs through an example conversion process. 

<!--
Describe changes in templates, and web site. Desirability to convert the legacy articles. Decided to convert latex input to Rmd, rather than directly html and why.

- R Journal latex template and formatting
- Quirks of the legacy articles
-->

# Converting from LaTeX to R Markdown

The decision to convert to R Markdown format means that the final output to pdf and HTML will depend on Pandoc [@pandoc].  Pandoc is a versatile document conversion program written in Haskell that is core to numerous documentation systems, including R Markdown and Quarto. Pandoc first converts a document into an abstract syntax tree. From this, it can convert to a different format, including custom ones. <!-- Although creating bespoke writers/readers in `Lua` can be challenging, pandoc includes filters that allow users to customize the output generated based on matching patterns plus some logic to modify them. -->

Pandoc can be used to do the conversion from LaTeX to R Markdown also. However, additional pre-processing needs to be done to handle special R Journal LaTeX styling. And further post-processing needs to be done to handle specific R Journal R Markdown styling. The \CRANpkg{texor} package contains functionality to handle this pre- and postprocessing of the document. 

<!-- uses these filters heavily, even for simple tasks like choosing which supporting figures to copy. A `Lua` filter constructs a list of image paths, stores them momentarily and the package uses this data to copy images. However, \CRANpkg{texor} also includes many pre-processing functions that employ regular expressions. This is needed to convert some text and LaTeX commands that are not recognized or handled by Pandoc. -->

**DC: Add a diagram here showing flow of work, just pre-process .tex -> pandoc -> lua ; rebib operations???**



<!-- **Maybe more details on the supporting packages here: LaTeX, Regex, pandoc building blocks of the packages, methods used in them [MOW]**-->

## Pre-processing using regular expressions 

LaTeX is very descriptive language, that allows authors substantial freedom for customization. Markdown [@markdown], on which R Markdown is based, is more restrictive and was born to make it easier to create web pages without the distraction of a gazillion HTML tags. The beauty of Markdown is that it allows the author to focus on writing, without format cluttering the text. The drawback is that it is simple typesetting, optimized for web delivery.

While pandoc can do most of the heavy-lifting, it cannot cope with all the freedom with which LaTeX documents are written. An example of this is with formatting of code. Pandoc only handles the `verbatim` environment, but there are many ways to format code in LaTeX, and the R Journal template has a special `\code{}` command. If the code environment is not verbatim, then pandoc will also try to process the actual code content as LaTeX commands and will likely lose details. It is better to convert these synonyms into `verbatim` environments this prior to passing the document to pandoc.

The functions in \CRANpkg{texor} that handle the pre-processing using regular expressions are:

- `stream_editor()`: operates like the `sed` function in unix [@unix] and allows generic text pattern matching and replacing.
- `patch_code_env()`: replaces the common code environments, `code`, `example`, `Sin`, `Sout`, `Scode`, `Sinput`, `smallverbatim`, `boxedverbatim`, `smallexample` with `verbatim`.
- `patch_equations()`: coordinates various equation environments.
- `patch_figure_env()`: coordinates various figure environments.
- `patch_table_env()`: coordinates table environments.

These functions are verbose and describe all the changes being made. They also create a backup of the original file before making the changes. 

<!-- by syntax though you can always embed HTML to expand the feature set. Although pandoc does most of the heavy lifting, there are some instances where even  filters cannot assist. A good demonstration of the issue in hand is code environments.-->

<!-- A limitation of pandoc is that it only works with a "verbatim" environment. However, in "RJournal",  we have multiple custom code environments which are not supported or defined due to lower-level tex limitations in pandoc. So the code  environments are eliminated during the conversion process. Including a Lua filter to find these elements and redefine them as verbatim environments would also be  ineffective. If the code environment is not verbatim, then pandoc will also try to process the actual code content as LaTeX commands and will lose out on details in some cases.-->

<!--**Be sure to mention the hard parts**-->


## Post-processing using Lua filters

Lua [@lua] is a programming language, that is light-weight, fast, ideal for procedural operations.  It is embedded in many other applications to allow custom scripting for extensibility. Pandoc allows users to provide custom lua filters to produce custom output formats. The \CRANpkg{texor} package handles post-processing of the R Markdown document into the special format for the R Journal using a suite of Lua filters. 

Here is an example of a Lua filter in \CRANpkg{texor}:

```Lua
function Div(el)
    if el.classes[1] == 'thebibliography' then
        return { }
    end
end
```

This filter reads the abstract syntax tree and filters out all the Div elements. Then it looks for the class "thebibliography." It turns out that this Div element  contains the LaTeX bibliographic records, which usually appear at the very end of papers. We don't need this portion in the article with the "RJ-web-article" layout,  given its inclusion as meta-data in the footer.

# Structure of the \CRANpkg{texor} package

**DC: List the main functions in an organised way, could be the pre-processing functions, the post-processing functions, utility functions. This can be also be summarized in a table, but there needs to be text explanations of the main functionality.**

# Using \CRANpkg{texor}

**Install instructions**

**Examples / getting started / usage and so on**


# Managing the bibliography using \CRANpkg{rebib}

## Overview

The \CRANpkg{rebib} package addresses the issue with LaTeX articles using  built-in bibliography options with or without BibTeX files. While this works  well with LaTeX, it won't work with Rmarkdown. Initially the goal was to use external software like Biber to convert the embedded bibliography to BibTeX. 
However the integration of external software was not viable, hence the experimental idea of a bibliography parser gained momentum. 

It was initially a part of the \CRANpkg{texor} package, as those functions grew in features and became more involved; at that point, it made sense to move those functions as a separate package. Initially, there were some reservations about 
the usage of \CRANpkg{rebib} and its stability with various formats. However, the package has improved over time and proven to be a good performer.

## Using \CRANpkg{rebib}
 
**Install instructions**

**Examples / getting started / usage and so on**
 
# Summary

Where this might be useful in the future, other applications.

# Acknowledgments
pandoc
 "TODO : Later"
 
# Supplementary materials

 github repos for the packages, texor, rebib, rjtools



